version: '3.8'

# Local development stack - NO CLOUD COSTS
# Uses free, open-source alternatives

services:
  # Qdrant Vector Database (replaces Azure AI Search)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks:
      - lineage-local

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - lineage-local

  # Local API (connects to Ollama on host)
  api:
    build:
      context: .
      dockerfile: Dockerfile.local
    container_name: lineage-api
    ports:
      - "8000:8000"
    environment:
      # Ollama runs on host machine
      - OLLAMA_HOST=http://host.docker.internal:11434
      - LLM_MODEL=llama3.1:8b
      - EMBEDDING_MODEL=nomic-embed-text
      # Local services
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # Local storage
      - STORAGE_PATH=/app/data
    volumes:
      - ./src:/app/src:ro
      - ./config:/app/config:ro
      - ./data:/app/data
    depends_on:
      - qdrant
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - lineage-local

  # Jupyter for exploration (optional)
  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: lineage-jupyter
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./src:/home/jovyan/src:ro
    networks:
      - lineage-local

volumes:
  qdrant-data:
  redis-data:

networks:
  lineage-local:
    driver: bridge
